{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e9351a0",
   "metadata": {},
   "source": [
    "# Temporal Difference Learning for 3D Tic Tac Toe\n",
    "\n",
    "This notebook contains the implementation of a Temporal Difference (TD) learning model using a Deep Q-Network (DQN) for playing 3D 4x4x4 Tic Tac Toe. The implementation is based on the approach outlined in the provided paper.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "261768de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Setting Directory\n",
    "os.chdir('C:/Users/Talha/OneDrive - Higher Education Commission/Documents/GitHub/reinforcement_learning/Project/')\n",
    "\n",
    "from python_scripts import state_formulation, utils, algorithm, tictactoe_4x4\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "import torch.nn.init as init\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97cae957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class customDotProduct(nn.Module):\n",
    "#     def __init__(self, input_size, output_size, block_size = 4):\n",
    "#         super(customDotProduct, self).__init__()\n",
    "#         self.input_size = input_size\n",
    "#         self.output_size = output_size\n",
    "#         self.block_size = block_size\n",
    "#         # Convert structure_weight to nn.Parameter\n",
    "#         self.structure_weight = torch.zeros((self.output_size, self.input_size))\n",
    "#         self.structure_weight = self.get_block_weights(self.structure_weight, block_size)\n",
    "#         self.structure_weight = nn.ParameterList([nn.Parameter(sw.float()) for sw in self.structure_weight])\n",
    "\n",
    "#     def get_block_weights(self, weight_list, block_size):\n",
    "#         for i in range(0, 304, block_size):\n",
    "#             weight_list[i: i + block_size, i: i + block_size] = init.xavier_normal_(torch.randn(block_size, block_size))\n",
    "#         learnable_blocks = [weight_list[i:i + block_size, i:i + block_size] for i in range(0, weight_list.shape[0], block_size)]\n",
    "#         updated = [block for block in learnable_blocks]\n",
    "#         return updated\n",
    "    \n",
    "#     def forward(self, feature_map):\n",
    "#         self.feature_map = [fm.float() for fm in feature_map]\n",
    "#         # Calculate dot products and concatenate along dim = 1\n",
    "#         concatenated_products = torch.cat([torch.matmul(fm.unsqueeze(0), sw) for fm, sw in zip(self.feature_map, self.structure_weight)], dim = 1)\n",
    "#         return concatenated_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8005ce71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing Code\n",
    "# weights = torch.zeros((304, 304))\n",
    "\n",
    "# block_size = 4\n",
    "# for i in range(0, 304, block_size):\n",
    "#     weights[i: i + block_size, i: i + block_size] = torch.ones(block_size, block_size)\n",
    "# learnable_blocks = [weights[i:i + block_size, i:i + block_size] for i in range(0, weights.shape[0], block_size)]\n",
    "# weights = [init.xavier_normal_(block) for block in learnable_blocks]\n",
    "\n",
    "# print(f'Before Update: Weights = {weights[0]} \\n')\n",
    "\n",
    "# # Assume some loss function and optimizer have been defined\n",
    "# custom_dot_product_module = customDotProduct(304, 304)\n",
    "# loss_function = nn.MSELoss()\n",
    "# optimizer = torch.optim.SGD(custom_dot_product_module.parameters(), lr = 0.01)\n",
    "\n",
    "# # Example training loop iteration\n",
    "# optimizer.zero_grad()  # Clear gradients\n",
    "# output = custom_dot_product_module(rows)  # Perform forward pass\n",
    "# loss = loss_function(output, torch.randn(1, 304))  # Compute loss\n",
    "# loss.backward()  # Perform backward pass\n",
    "# optimizer.step()  # Update weights\n",
    "# print(f'After Update: Weights = {custom_dot_product_module.structure_weight[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba55757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class StructuredLinear(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(StructuredLinear, self).__init__()\n",
    "\n",
    "#     def get_rows(self, input_tensor):\n",
    "#         # Get diagonals (across 2 faces),digonals (across 3 faces) and horizontal and vertical rows\n",
    "#         diag_two_faces = []\n",
    "#         diag_two_faces.extend(\n",
    "#             [torch.diagonal(input_tensor[i, :, :]), torch.diagonal(input_tensor[:, i, :]), torch.diagonal(input_tensor[:, :, i]), \n",
    "#             torch.diagonal(torch.fliplr(input_tensor)[i, :, :]), torch.diagonal(torch.fliplr(input_tensor)[:, i, :]), torch.diagonal(torch.fliplr(input_tensor)[:, :, i])] \n",
    "#             for i in range(input_tensor.shape[0]))\n",
    "#         diag_two_faces = [item for sublist in diag_two_faces for item in sublist]\n",
    "        \n",
    "#         diag_three_faces = []\n",
    "#         diag_three_faces = [[[[input_tensor[i, i, i], input_tensor[3 - i, i, i], input_tensor[i, 3 - i, i], input_tensor[i, i, 3 - i]] \n",
    "#                             for i in range(4)][k][j] for j in range(4) for k in range(4)][l:l + 4] for l in range(0, 16, 4)]\n",
    "#         diag_three_faces = [torch.tensor([t.item() for t in row]) for row in diag_three_faces]\n",
    "\n",
    "#         horizontal_and_vertical_rows = []\n",
    "#         horizontal_and_vertical_rows.extend([input_tensor[i, j, :], input_tensor[i, :, j], input_tensor[:, i, j]]\n",
    "#                                             for i in range(input_tensor.shape[0]) for j in range(input_tensor.shape[0]))\n",
    "#         horizontal_and_vertical_rows = [item for sublist in horizontal_and_vertical_rows for item in sublist]\n",
    "        \n",
    "#         return horizontal_and_vertical_rows + diag_two_faces + diag_three_faces\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         rows = self.get_rows(x)\n",
    "#         return rows\n",
    "\n",
    "# class MyNeuralNetwork(nn.Module, tictactoe_4x4.TicTacToe4x4x4):\n",
    "#     def __init__(self, num_detectors):\n",
    "#         super(MyNeuralNetwork, self).__init__()\n",
    "\n",
    "#         self.num_detectors = num_detectors\n",
    "#         self.structured_layer = StructuredLinear()\n",
    "        \n",
    "#         self.custom_operation_layer = customDotProduct(input_size = num_detectors * 4, output_size = num_detectors * 4)\n",
    "\n",
    "#         self.second_layer = nn.Linear(num_detectors * 4, 32, bias = False)\n",
    "#         init.xavier_normal_(self.second_layer.weight)\n",
    "\n",
    "#         self.output_layer = nn.Linear(32, 1, bias = False)\n",
    "#         self.act = nn.Tanh()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.structured_layer(x)\n",
    "#         x = self.custom_operation_layer(x)\n",
    "#         x = self.act(x) # --> Tanh\n",
    "#         x = self.second_layer(x)\n",
    "#         x = self.act(x)\n",
    "#         x = self.output_layer(x)\n",
    "#         return x\n",
    "    \n",
    "# # Instantiate Model\n",
    "# model = MyNeuralNetwork(num_detectors = 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a36f363",
   "metadata": {},
   "outputs": [],
   "source": [
    "class customDotProduct(nn.Module):\n",
    "    def __init__(self, input_size, output_size, block_size = 4):\n",
    "        super(customDotProduct, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.block_size = block_size\n",
    "        # Convert structure_weight to nn.Parameter\n",
    "        self.structure_weight = torch.zeros((self.output_size, self.input_size))\n",
    "        self.structure_weight = self.get_block_weights(self.structure_weight, block_size)\n",
    "        self.structure_weight = nn.ParameterList([nn.Parameter(sw.float()) for sw in self.structure_weight])\n",
    "\n",
    "    def get_block_weights(self, weight_list, block_size):\n",
    "        for i in range(0, 304, block_size):\n",
    "            weight_list[i: i + block_size, i: i + block_size] = init.xavier_normal_(torch.randn(block_size, block_size))\n",
    "        learnable_blocks = [weight_list[i:i + block_size, i:i + block_size] for i in range(0, weight_list.shape[0], block_size)]\n",
    "        updated = [block for block in learnable_blocks]\n",
    "        return updated\n",
    "    \n",
    "    def forward(self, feature_map):\n",
    "        self.feature_map = [fm.float() for fm in feature_map]\n",
    "        # Calculate dot products and concatenate along dim = 1\n",
    "        concatenated_products = torch.cat([torch.matmul(fm.unsqueeze(0), sw) for fm, sw in zip(self.feature_map, self.structure_weight)], dim = 1)\n",
    "        return concatenated_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c09ad6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StructuredLinear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StructuredLinear, self).__init__()\n",
    "\n",
    "    def get_rows(self, input_tensor):\n",
    "        # Get diagonals (across 2 faces),digonals (across 3 faces) and horizontal and vertical rows\n",
    "        diag_two_faces = []\n",
    "        diag_two_faces.extend(\n",
    "            [torch.diagonal(input_tensor[i, :, :]), torch.diagonal(input_tensor[:, i, :]), torch.diagonal(input_tensor[:, :, i]), \n",
    "            torch.diagonal(torch.fliplr(input_tensor)[i, :, :]), torch.diagonal(torch.fliplr(input_tensor)[:, i, :]), torch.diagonal(torch.fliplr(input_tensor)[:, :, i])] \n",
    "            for i in range(input_tensor.shape[0]))\n",
    "        diag_two_faces = [item for sublist in diag_two_faces for item in sublist]\n",
    "        \n",
    "        diag_three_faces = []\n",
    "        diag_three_faces = [[[[input_tensor[i, i, i], input_tensor[3 - i, i, i], input_tensor[i, 3 - i, i], input_tensor[i, i, 3 - i]] \n",
    "                            for i in range(4)][k][j] for j in range(4) for k in range(4)][l:l + 4] for l in range(0, 16, 4)]\n",
    "        diag_three_faces = [torch.tensor([t.item() for t in row]) for row in diag_three_faces]\n",
    "\n",
    "        horizontal_and_vertical_rows = []\n",
    "        horizontal_and_vertical_rows.extend([input_tensor[i, j, :], input_tensor[i, :, j], input_tensor[:, i, j]]\n",
    "                                            for i in range(input_tensor.shape[0]) for j in range(input_tensor.shape[0]))\n",
    "        horizontal_and_vertical_rows = [item for sublist in horizontal_and_vertical_rows for item in sublist]\n",
    "        \n",
    "        return horizontal_and_vertical_rows + diag_two_faces + diag_three_faces\n",
    "\n",
    "    def forward(self, x):\n",
    "        rows = self.get_rows(x)\n",
    "        return rows\n",
    "\n",
    "class MyNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNeuralNetwork, self).__init__()\n",
    "        self.structured_layer = StructuredLinear()\n",
    "        \n",
    "        self.custom_operation_layer = customDotProduct(input_size = 304, output_size = 304)\n",
    "\n",
    "        self.second_layer = nn.Linear(304, 32, bias = False)\n",
    "        init.xavier_normal_(self.second_layer.weight)\n",
    "\n",
    "        self.output_layer = nn.Linear(32, 1, bias = False)\n",
    "        self.act = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.structured_layer(x)\n",
    "        x = self.custom_operation_layer(x)\n",
    "        x = self.act(x) # --> Tanh\n",
    "        x = self.second_layer(x)\n",
    "        x = self.act(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "    \n",
    "# Example usage\n",
    "model= MyNeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "760d3665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "MyNeuralNetwork                          [4, 4, 4]                 [1, 1]                    --\n",
       "├─StructuredLinear: 1-1                  [4, 4, 4]                 [4]                       --\n",
       "├─customDotProduct: 1-2                  [4]                       [1, 304]                  1,216\n",
       "├─Tanh: 1-3                              [1, 304]                  [1, 304]                  --\n",
       "├─Linear: 1-4                            [1, 304]                  [1, 32]                   9,728\n",
       "├─Tanh: 1-5                              [1, 32]                   [1, 32]                   --\n",
       "├─Linear: 1-6                            [1, 32]                   [1, 1]                    32\n",
       "===================================================================================================================\n",
       "Total params: 10,976\n",
       "Trainable params: 10,976\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.01\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.04\n",
       "Estimated Total Size (MB): 0.04\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_size = [4, 4, 4], col_names = ['input_size', 'output_size', 'num_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e6fb543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "loss_function = nn.SmoothL1Loss()\n",
    "EPSILON = 0.1\n",
    "GAMMA = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b63194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def e_greedy(value_dict):\n",
    "    if np.random.random() > EPSILON:\n",
    "        return max(value_dict, key = lambda k: value_dict[k])\n",
    "    else:\n",
    "        return random.choice(list(value_dict.items()))[0]\n",
    "\n",
    "def func_modify(afterstate):\n",
    "    return torch.tensor([[[1 if cell == \"X\" else -1 if cell == \"O\" else 0 for cell in row] for row in layer] for layer in afterstate])\n",
    "\n",
    "def benchmark_policy_for_player2(action_list):\n",
    "    return np.random.choice(action_list)\n",
    "\n",
    "def train_td_model(model, num_episodes):\n",
    "    overall_loss = []\n",
    "    for episode in tqdm(range(num_episodes)):\n",
    "        env = tictactoe_4x4.TicTacToe4x4x4()\n",
    "\n",
    "        terminated = False\n",
    "        current_state = torch.zeros((64))\n",
    "        reward = 0\n",
    "        player_turn = \"X\"\n",
    "        prev_afterstate = None\n",
    "        time_idx = 0\n",
    "        loss_list = []\n",
    "\n",
    "        while not terminated:\n",
    "            time_idx += 1\n",
    "            # Get actions space\n",
    "            action_space = env.get_action_space()\n",
    "            value_dict = {}\n",
    "            for action in action_space:\n",
    "                copy_tensor = current_state.detach().clone()\n",
    "                copy_tensor[action] = 1\n",
    "                value_dict[action] = model.forward(copy_tensor.view(4, 4, 4))\n",
    "            \n",
    "            # Here we choose action based on epsilon greedy\n",
    "            action = e_greedy(value_dict)\n",
    "            \n",
    "            current_state, reward, terminated, player_turn = env.step(action) # afterstate\n",
    "\n",
    "            if time_idx != 1:\n",
    "                v_new = reward + (GAMMA * model.forward(func_modify(current_state)))\n",
    "                v = model.forward(func_modify(prev_afterstate))\n",
    "                loss = loss_function(v, v_new)\n",
    "                loss_list.append(loss.item())\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            prev_afterstate = current_state\n",
    "            # Player 2 -- use benchmark\n",
    "            player_2_action_space = env.get_action_space()\n",
    "            player_2_move = benchmark_policy_for_player2(player_2_action_space)\n",
    "            current_state, reward, terminated, player_turn = env.step(player_2_move)\n",
    "            \n",
    "            current_state = func_modify(current_state).view(64)\n",
    "\n",
    "        mean_loss = np.mean(loss_list)\n",
    "        print(f'Episode: {episode + 1}, Loss: {mean_loss}')\n",
    "        overall_loss.append(mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38ef1c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e65e56383d8842819108c917b31fd1ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Loss: 0.027332383097308503\n",
      "Episode: 2, Loss: 5.1807438116956526e-05\n",
      "Episode: 3, Loss: 0.00019809241865957681\n",
      "Episode: 4, Loss: 0.0003479837768656366\n",
      "Episode: 5, Loss: 0.025106080801919006\n",
      "Episode: 6, Loss: 0.01963167903727005\n",
      "Episode: 7, Loss: 0.021663222897347605\n",
      "Episode: 8, Loss: 0.0006128902910542978\n",
      "Episode: 9, Loss: 0.000210248991799705\n",
      "Episode: 10, Loss: 0.021815336566850786\n",
      "Episode: 11, Loss: 0.02595562695856451\n",
      "Episode: 12, Loss: 0.0006484965807445064\n",
      "Episode: 13, Loss: 0.002475650533122699\n",
      "Episode: 14, Loss: 7.743617253671194e-05\n",
      "Episode: 15, Loss: 0.0008059130394450711\n",
      "Episode: 16, Loss: 0.0001395504700754244\n",
      "Episode: 17, Loss: 0.028112671797819195\n",
      "Episode: 18, Loss: 0.0013305847987094938\n",
      "Episode: 19, Loss: 5.7880113849427696e-05\n",
      "Episode: 20, Loss: 0.00010876695018320207\n",
      "Episode: 21, Loss: 0.00022659868182017817\n",
      "Episode: 22, Loss: 0.00014484774108068117\n",
      "Episode: 23, Loss: 0.029176112286971628\n",
      "Episode: 24, Loss: 0.03018881896342825\n",
      "Episode: 25, Loss: 0.02953280595045366\n",
      "Episode: 26, Loss: 0.0005849175347975688\n",
      "Episode: 27, Loss: 0.036643410907485165\n",
      "Episode: 28, Loss: 0.0016485673304487136\n",
      "Episode: 29, Loss: 0.03101137074336293\n",
      "Episode: 30, Loss: 0.0014812947457314642\n",
      "Episode: 31, Loss: 0.0006921873757467741\n",
      "Episode: 32, Loss: 0.0014814473726750697\n",
      "Episode: 33, Loss: 0.00014924728032606924\n",
      "Episode: 34, Loss: 0.020414797540171097\n",
      "Episode: 35, Loss: 0.00016185491321607515\n",
      "Episode: 36, Loss: 0.021786963723846278\n",
      "Episode: 37, Loss: 0.0008730757313862662\n",
      "Episode: 38, Loss: 0.0004852914573802991\n",
      "Episode: 39, Loss: 0.0001675294177164774\n",
      "Episode: 40, Loss: 0.00014967914228236623\n",
      "Episode: 41, Loss: 9.99125359024166e-05\n",
      "Episode: 42, Loss: 0.00019434352826566383\n",
      "Episode: 43, Loss: 0.00023448534444665055\n",
      "Episode: 44, Loss: 0.00013008838023237704\n",
      "Episode: 45, Loss: 0.0001777571309759196\n",
      "Episode: 46, Loss: 6.23530620104545e-05\n",
      "Episode: 47, Loss: 8.225865888076913e-05\n",
      "Episode: 48, Loss: 5.459611364244665e-05\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "num_episodes = 1000  # Number of episodes for training\n",
    "loss = train_td_model(model, num_episodes)  # Train the model\n",
    "\n",
    "# Save the trained model\n",
    "# os.makedirs('C:/Users/Talha/OneDrive - Higher Education Commission/Documents/GitHub/reinforcement_learning/Project/Phase_3_3D_Tic_Tac_Toe/models', exist_ok = True)\n",
    "# model_path = 'C:/Users/Talha/OneDrive - Higher Education Commission/Documents/GitHub/reinforcement_learning/Project/Phase_3_3D_Tic_Tac_Toe/models/td_tictactoe_model.pth'\n",
    "# save_model(model, model_path)\n",
    "\n",
    "# model_path\n",
    "\n",
    "# 1) Turn all of this to device compatible - (cuda) (train for 1000 episodes and store weights every 100)\n",
    "# 2) Once the model has been trained, make a function which recieves the models weights and the Neural Network Object and the current action space and state\n",
    "# the function takes the weights, and inserts them into the neural network object and computes forward pass for each of the possible transitions and returns\n",
    "# the action corresponding to the maximum value. Be careful as the state that is being passed is a list of lists of lists. So to make that compatible to the\n",
    "# forward pass, use the func_modify function to get it into a 3D tensor form. Also remember to convert each of the actions (in integer form) to coardinates\n",
    "# form using the get_coardinates function. Then transition using those coardinates. Once you have now computed the maximum action value, convert it back\n",
    "# to integer using get_position and that will be returned\n",
    "\n",
    "# Inference Loop - u will play ur policy (gotten from above function) with another baseline policy like random for the other player. Count the number of\n",
    "# ones/ minus ones/zeros and report % win, % loss, % draw.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d4e555",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
