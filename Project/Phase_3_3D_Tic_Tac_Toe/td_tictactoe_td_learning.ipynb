{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e9351a0",
   "metadata": {},
   "source": [
    "# Temporal Difference Learning for 3D Tic Tac Toe\n",
    "\n",
    "This notebook contains the implementation of a Temporal Difference (TD) learning model using a Deep Q-Network (DQN) for playing 3D 4x4x4 Tic Tac Toe. The implementation is based on the approach outlined in the provided paper.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "261768de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Setting Directory\n",
    "os.chdir('C:/Users/Talha/OneDrive - Higher Education Commission/Documents/GitHub/reinforcement_learning/Project/')\n",
    "\n",
    "from python_scripts import state_formulation, utils, algorithm, tictactoe_4x4\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "import torch.nn.init as init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "5a1cd2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rows(input_tensor):\n",
    "    # Get diagonals (across 2 faces),digonals (across 3 faces) and horizontal and vertical rows\n",
    "    diag_two_faces = []\n",
    "    diag_two_faces.extend(\n",
    "        [torch.diagonal(input_tensor[i, :, :]), torch.diagonal(input_tensor[:, i, :]), torch.diagonal(input_tensor[:, :, i]), \n",
    "        torch.diagonal(torch.fliplr(input_tensor)[i, :, :]), torch.diagonal(torch.fliplr(input_tensor)[:, i, :]), torch.diagonal(torch.fliplr(input_tensor)[:, :, i])] \n",
    "        for i in range(input_tensor.shape[0]))\n",
    "    diag_two_faces = [item for sublist in diag_two_faces for item in sublist]\n",
    "    \n",
    "    diag_three_faces = []\n",
    "    diag_three_faces = [[[[input_tensor[i, i, i], input_tensor[3 - i, i, i], input_tensor[i, 3 - i, i], input_tensor[i, i, 3 - i]] \n",
    "                          for i in range(4)][k][j] for j in range(4) for k in range(4)][l:l + 4] for l in range(0, 16, 4)]\n",
    "    diag_three_faces = [torch.tensor([t.item() for t in row]) for row in diag_three_faces]\n",
    "\n",
    "    horizontal_and_vertical_rows = []\n",
    "    horizontal_and_vertical_rows.extend([input_tensor[i, j, :], input_tensor[i, :, j], input_tensor[:, i, j]]\n",
    "                                        for i in range(input_tensor.shape[0]) for j in range(input_tensor.shape[0]))\n",
    "    horizontal_and_vertical_rows = [item for sublist in horizontal_and_vertical_rows for item in sublist]\n",
    "    \n",
    "    return horizontal_and_vertical_rows + diag_two_faces + diag_three_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "cb2576da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 76\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.arange(64).view(4, 4, 4)\n",
    "overall_rows = get_rows(input_tensor)\n",
    "print(f'Number of rows: {len(overall_rows)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "97cae957",
   "metadata": {},
   "outputs": [],
   "source": [
    "class customDotProduct(nn.Module):\n",
    "    def __init__(self, structure_weight, block_size):\n",
    "        super(customDotProduct, self).__init__()\n",
    "        self.block_size = block_size\n",
    "        # Convert structure_weight to nn.Parameter\n",
    "        self.structure_weight = self.get_block_weights(structure_weight, block_size)\n",
    "        self.structure_weight = nn.ParameterList([nn.Parameter(sw.float()) for sw in self.structure_weight])\n",
    "\n",
    "    def get_block_weights(self, weight_list, block_size):\n",
    "        for i in range(0, 304, block_size):\n",
    "            weight_list[i: i + block_size, i: i + block_size] = torch.ones(block_size, block_size)\n",
    "        learnable_blocks = [weight_list[i:i + block_size, i:i + block_size] for i in range(0, weight_list.shape[0], block_size)]\n",
    "        updated = [block for block in learnable_blocks]\n",
    "        return updated\n",
    "    \n",
    "    def forward(self, feature_map):\n",
    "        self.feature_map = [fm.float() for fm in feature_map]\n",
    "        # Calculate dot products and concatenate along dim=1\n",
    "        concatenated_products = torch.cat([torch.matmul(fm.unsqueeze(0), sw) for fm, sw in zip(self.feature_map, self.structure_weight)], dim = 1)\n",
    "        return concatenated_products\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "8005ce71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Code\n",
    "# weights = torch.zeros((304, 304))\n",
    "\n",
    "# block_size = 4\n",
    "# for i in range(0, 304, block_size):\n",
    "#     weights[i: i + block_size, i: i + block_size] = torch.ones(block_size, block_size)\n",
    "# learnable_blocks = [weights[i:i + block_size, i:i + block_size] for i in range(0, weights.shape[0], block_size)]\n",
    "# weights = [init.xavier_normal_(block) for block in learnable_blocks]\n",
    "\n",
    "# print(f'Before Update: Weights = {weights[0]} \\n')\n",
    "\n",
    "# # Assume some loss function and optimizer have been defined\n",
    "# custom_dot_product_module = customDotProduct(weights, 4)\n",
    "# loss_function = nn.MSELoss()\n",
    "# optimizer = torch.optim.SGD(custom_dot_product_module.parameters(), lr = 0.01)\n",
    "\n",
    "# # Example training loop iteration\n",
    "# optimizer.zero_grad()  # Clear gradients\n",
    "# output = custom_dot_product_module(overall_rows)  # Perform forward pass\n",
    "# loss = loss_function(output, torch.randn(1, 304))  # Compute loss\n",
    "# loss.backward()  # Perform backward pass\n",
    "# optimizer.step()  # Update weights\n",
    "# print(f'After Update: Weights = {custom_dot_product_module.structure_weight[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "1ba55757",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StructuredLinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size, block_size = 4):\n",
    "        super(StructuredLinear, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.block_size = block_size\n",
    "\n",
    "        # Initialize weights and biases\n",
    "        self.weights = nn.init.xavier_normal_(torch.zeros((output_size, input_size)))\n",
    "        self.act = nn.Tanh()\n",
    "\n",
    "    def get_rows(self, input_tensor):\n",
    "        # Get diagonals (across 2 faces),digonals (across 3 faces) and horizontal and vertical rows\n",
    "        diag_two_faces = []\n",
    "        diag_two_faces.extend(\n",
    "            [torch.diagonal(input_tensor[i, :, :]), torch.diagonal(input_tensor[:, i, :]), torch.diagonal(input_tensor[:, :, i]), \n",
    "            torch.diagonal(torch.fliplr(input_tensor)[i, :, :]), torch.diagonal(torch.fliplr(input_tensor)[:, i, :]), torch.diagonal(torch.fliplr(input_tensor)[:, :, i])] \n",
    "            for i in range(input_tensor.shape[0]))\n",
    "        diag_two_faces = [item for sublist in diag_two_faces for item in sublist]\n",
    "        \n",
    "        diag_three_faces = []\n",
    "        diag_three_faces = [[[[input_tensor[i, i, i], input_tensor[3 - i, i, i], input_tensor[i, 3 - i, i], input_tensor[i, i, 3 - i]] \n",
    "                            for i in range(4)][k][j] for j in range(4) for k in range(4)][l:l + 4] for l in range(0, 16, 4)]\n",
    "        diag_three_faces = [torch.tensor([t.item() for t in row]) for row in diag_three_faces]\n",
    "\n",
    "        horizontal_and_vertical_rows = []\n",
    "        horizontal_and_vertical_rows.extend([input_tensor[i, j, :], input_tensor[i, :, j], input_tensor[:, i, j]]\n",
    "                                            for i in range(input_tensor.shape[0]) for j in range(input_tensor.shape[0]))\n",
    "        horizontal_and_vertical_rows = [item for sublist in horizontal_and_vertical_rows for item in sublist]\n",
    "        \n",
    "        return horizontal_and_vertical_rows + diag_two_faces + diag_three_faces\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(\"RR\")\n",
    "        rows = self.get_rows(x)\n",
    "        print(\"GG\")\n",
    "        custom_init = customDotProduct(self.weights, self.block_size)\n",
    "        print(\"!!\")\n",
    "        result = custom_init.forward(rows)\n",
    "        print(\"#$#\")\n",
    "        return result\n",
    "\n",
    "class MyNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNeuralNetwork, self).__init__()\n",
    "        self.structured_layer = StructuredLinear(304, 304)\n",
    "        self.second_layer = nn.Linear(304, 32, bias = False)\n",
    "        init.xavier_normal_(self.second_layer.weight)\n",
    "        self.output_layer = nn.Linear(32, 1, bias = False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.structured_layer(x)\n",
    "        print(x)\n",
    "        # x = self.act(x) # --> Tanh\n",
    "        print(\"2\")\n",
    "        x = self.second_layer(x)\n",
    "        print(\"3\")\n",
    "        # x = self.act(x)\n",
    "        print(\"4\")\n",
    "        x = self.output_layer(x)\n",
    "        print(\"5\")\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "model = MyNeuralNetwork()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "5463f972",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.randn(4, 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "760d3665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RR\n",
      "GG\n",
      "!!\n",
      "#$#\n",
      "tensor([[-0.0462, -0.0462, -0.0462, -0.0462, -0.2330, -0.2330, -0.2330, -0.2330,\n",
      "          0.9862,  0.9862,  0.9862,  0.9862,  2.2830,  2.2830,  2.2830,  2.2830,\n",
      "         -0.7087, -0.7087, -0.7087, -0.7087, -0.4895, -0.4895, -0.4895, -0.4895,\n",
      "          0.4043,  0.4043,  0.4043,  0.4043,  1.8118,  1.8118,  1.8118,  1.8118,\n",
      "          0.5791,  0.5791,  0.5791,  0.5791,  1.0230,  1.0230,  1.0230,  1.0230,\n",
      "          2.7939,  2.7939,  2.7939,  2.7939,  0.9883,  0.9883,  0.9883,  0.9883,\n",
      "          0.5562,  0.5562,  0.5562,  0.5562,  2.5767,  2.5767,  2.5767,  2.5767,\n",
      "          3.1591,  3.1591,  3.1591,  3.1591,  1.2641,  1.2641,  1.2641,  1.2641,\n",
      "         -2.7488, -2.7488, -2.7488, -2.7488, -0.2804, -0.2804, -0.2804, -0.2804,\n",
      "         -0.7418, -0.7418, -0.7418, -0.7418,  0.7623,  0.7623,  0.7623,  0.7623,\n",
      "          4.1820,  4.1820,  4.1820,  4.1820, -2.2008, -2.2008, -2.2008, -2.2008,\n",
      "         -1.7125, -1.7125, -1.7125, -1.7125, -0.3943, -0.3943, -0.3943, -0.3943,\n",
      "          0.5919,  0.5919,  0.5919,  0.5919,  2.8092,  2.8092,  2.8092,  2.8092,\n",
      "          1.9593,  1.9593,  1.9593,  1.9593,  2.7585,  2.7585,  2.7585,  2.7585,\n",
      "         -1.2889, -1.2889, -1.2889, -1.2889, -2.8919, -2.8919, -2.8919, -2.8919,\n",
      "          0.6351,  0.6351,  0.6351,  0.6351,  1.4609,  1.4609,  1.4609,  1.4609,\n",
      "         -0.8978, -0.8978, -0.8978, -0.8978,  1.0969,  1.0969,  1.0969,  1.0969,\n",
      "          2.1013,  2.1013,  2.1013,  2.1013,  0.3657,  0.3657,  0.3657,  0.3657,\n",
      "          0.9622,  0.9622,  0.9622,  0.9622,  1.4481,  1.4481,  1.4481,  1.4481,\n",
      "          0.4965,  0.4965,  0.4965,  0.4965,  0.3608,  0.3608,  0.3608,  0.3608,\n",
      "          0.7109,  0.7109,  0.7109,  0.7109, -0.3738, -0.3738, -0.3738, -0.3738,\n",
      "         -1.7623, -1.7623, -1.7623, -1.7623, -1.1047, -1.1047, -1.1047, -1.1047,\n",
      "         -0.9329, -0.9329, -0.9329, -0.9329,  1.5356,  1.5356,  1.5356,  1.5356,\n",
      "          0.0419,  0.0419,  0.0419,  0.0419,  2.2650,  2.2650,  2.2650,  2.2650,\n",
      "          1.4504,  1.4504,  1.4504,  1.4504,  0.0208,  0.0208,  0.0208,  0.0208,\n",
      "          1.1051,  1.1051,  1.1051,  1.1051, -1.8578, -1.8578, -1.8578, -1.8578,\n",
      "         -1.2734, -1.2734, -1.2734, -1.2734,  1.7291,  1.7291,  1.7291,  1.7291,\n",
      "          0.3402,  0.3402,  0.3402,  0.3402,  0.7916,  0.7916,  0.7916,  0.7916,\n",
      "          0.5170,  0.5170,  0.5170,  0.5170, -0.1187, -0.1187, -0.1187, -0.1187,\n",
      "         -1.0179, -1.0179, -1.0179, -1.0179, -1.7649, -1.7649, -1.7649, -1.7649,\n",
      "         -0.7493, -0.7493, -0.7493, -0.7493, -1.0179, -1.0179, -1.0179, -1.0179,\n",
      "          0.8807,  0.8807,  0.8807,  0.8807,  3.2059,  3.2059,  3.2059,  3.2059,\n",
      "          0.7916,  0.7916,  0.7916,  0.7916,  1.7839,  1.7839,  1.7839,  1.7839,\n",
      "          1.0317,  1.0317,  1.0317,  1.0317, -1.2734, -1.2734, -1.2734, -1.2734,\n",
      "          0.8858,  0.8858,  0.8858,  0.8858,  1.5455,  1.5455,  1.5455,  1.5455,\n",
      "          0.0208,  0.0208,  0.0208,  0.0208,  2.2537,  2.2537,  2.2537,  2.2537,\n",
      "          0.4045,  0.4045,  0.4045,  0.4045,  1.8591,  1.8591,  1.8591,  1.8591,\n",
      "         -0.1221, -0.1221, -0.1221, -0.1221,  0.7355,  0.7355,  0.7355,  0.7355]])\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "MyNeuralNetwork                          [4, 4, 4]                 [1, 1]                    --\n",
       "├─StructuredLinear: 1-1                  [4, 4, 4]                 [1, 304]                  --\n",
       "├─Linear: 1-2                            [1, 304]                  [1, 32]                   9,728\n",
       "├─Linear: 1-3                            [1, 32]                   [1, 1]                    32\n",
       "===================================================================================================================\n",
       "Total params: 9,760\n",
       "Trainable params: 9,760\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.01\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.04\n",
       "Estimated Total Size (MB): 0.04\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_data = input_tensor, col_names = ['input_size', 'output_size', 'num_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "25243f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RR\n",
      "GG\n",
      "!!\n",
      "#$#\n"
     ]
    }
   ],
   "source": [
    "d = StructuredLinear(304, 304, 4)\n",
    "f = d(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "7064a834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5902, -0.5902, -0.5902, -0.5902, -0.9876, -0.9876, -0.9876, -0.9876,\n",
       "          0.7733,  0.7733,  0.7733,  0.7733, -0.7729, -0.7729, -0.7729, -0.7729,\n",
       "         -0.9977, -0.9977, -0.9977, -0.9977, -0.4742, -0.4742, -0.4742, -0.4742,\n",
       "         -0.1815, -0.1815, -0.1815, -0.1815,  0.0666,  0.0666,  0.0666,  0.0666,\n",
       "         -0.1981, -0.1981, -0.1981, -0.1981, -0.8992, -0.8992, -0.8992, -0.8992,\n",
       "          0.9865,  0.9865,  0.9865,  0.9865, -0.9318, -0.9318, -0.9318, -0.9318,\n",
       "          0.9077,  0.9077,  0.9077,  0.9077,  0.2671,  0.2671,  0.2671,  0.2671,\n",
       "         -0.9999, -0.9999, -0.9999, -0.9999, -0.5330, -0.5330, -0.5330, -0.5330,\n",
       "          0.9852,  0.9852,  0.9852,  0.9852, -0.1272, -0.1272, -0.1272, -0.1272,\n",
       "          0.9627,  0.9627,  0.9627,  0.9627, -0.0704, -0.0704, -0.0704, -0.0704,\n",
       "         -0.6843, -0.6843, -0.6843, -0.6843,  0.6885,  0.6885,  0.6885,  0.6885,\n",
       "          0.7982,  0.7982,  0.7982,  0.7982,  0.7845,  0.7845,  0.7845,  0.7845,\n",
       "         -0.3858, -0.3858, -0.3858, -0.3858, -0.4561, -0.4561, -0.4561, -0.4561,\n",
       "         -0.2909, -0.2909, -0.2909, -0.2909, -0.6459, -0.6459, -0.6459, -0.6459,\n",
       "         -0.7776, -0.7776, -0.7776, -0.7776,  0.5044,  0.5044,  0.5044,  0.5044,\n",
       "          0.1639,  0.1639,  0.1639,  0.1639, -0.3117, -0.3117, -0.3117, -0.3117,\n",
       "          0.6399,  0.6399,  0.6399,  0.6399, -0.7909, -0.7909, -0.7909, -0.7909,\n",
       "         -0.2254, -0.2254, -0.2254, -0.2254,  0.9999,  0.9999,  0.9999,  0.9999,\n",
       "         -0.9457, -0.9457, -0.9457, -0.9457, -0.3805, -0.3805, -0.3805, -0.3805,\n",
       "          0.8225,  0.8225,  0.8225,  0.8225, -0.9883, -0.9883, -0.9883, -0.9883,\n",
       "         -0.9916, -0.9916, -0.9916, -0.9916, -0.9998, -0.9998, -0.9998, -0.9998,\n",
       "          0.9996,  0.9996,  0.9996,  0.9996,  0.9372,  0.9372,  0.9372,  0.9372,\n",
       "          0.9313,  0.9313,  0.9313,  0.9313, -0.3376, -0.3376, -0.3376, -0.3376,\n",
       "          0.7278,  0.7278,  0.7278,  0.7278, -0.2605, -0.2605, -0.2605, -0.2605,\n",
       "          0.3614,  0.3614,  0.3614,  0.3614,  0.8055,  0.8055,  0.8055,  0.8055,\n",
       "         -0.1062, -0.1062, -0.1062, -0.1062, -0.7033, -0.7033, -0.7033, -0.7033,\n",
       "          0.9748,  0.9748,  0.9748,  0.9748, -0.6920, -0.6920, -0.6920, -0.6920,\n",
       "         -0.5524, -0.5524, -0.5524, -0.5524, -0.9944, -0.9944, -0.9944, -0.9944,\n",
       "         -0.9982, -0.9982, -0.9982, -0.9982, -0.2757, -0.2757, -0.2757, -0.2757,\n",
       "          0.1514,  0.1514,  0.1514,  0.1514, -0.9976, -0.9976, -0.9976, -0.9976,\n",
       "          0.2857,  0.2857,  0.2857,  0.2857,  0.1514,  0.1514,  0.1514,  0.1514,\n",
       "         -0.5783, -0.5783, -0.5783, -0.5783, -0.9946, -0.9946, -0.9946, -0.9946,\n",
       "         -0.9944, -0.9944, -0.9944, -0.9944, -0.5330, -0.5330, -0.5330, -0.5330,\n",
       "          0.8720,  0.8720,  0.8720,  0.8720,  0.9748,  0.9748,  0.9748,  0.9748,\n",
       "          0.9926,  0.9926,  0.9926,  0.9926,  0.9974,  0.9974,  0.9974,  0.9974,\n",
       "          0.8055,  0.8055,  0.8055,  0.8055,  0.9920,  0.9920,  0.9920,  0.9920,\n",
       "          0.7172,  0.7172,  0.7172,  0.7172, -0.9716, -0.9716, -0.9716, -0.9716,\n",
       "          0.9441,  0.9441,  0.9441,  0.9441, -0.1623, -0.1623, -0.1623, -0.1623]],\n",
       "       grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act = nn.Tanh()\n",
    "act(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cec3583e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the MLP architecture for the TD learning model\n",
    "class TDNetwork(nn.Module, tictactoe_4x4.TicTacToe4x4x4):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        # Note: Hidden Sizes will be a list. According to the paper, it will be 304, 32\n",
    "        super(TDNetwork, self).__init__()\n",
    "        layers = []\n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.append(nn.Linear(input_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_size = hidden_size\n",
    "        layers.append(nn.Linear(hidden_sizes[-1], output_size))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        feature_map = get_rows(x)\n",
    "        return self.layers(feature_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a13fb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linears = nn.ModuleList([nn.Linear(10, 10) for i in range(10)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ModuleList can act as an iterable, or be indexed using ints\n",
    "        for i, l in enumerate(self.linears):\n",
    "            x = self.linears[i // 2](x) + l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5c406d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TD learning model\n",
    "input_size = 64  # Assuming each space on the 4x4x4 board is represented as a binary (occupied or not)\n",
    "hidden_sizes = [128, 128]  # Hidden layers sizes as per the paper's experimentation\n",
    "output_size = 1  # Output size representing the value function\n",
    "model = TDNetwork(input_size, hidden_sizes, output_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e6fb543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_function = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b63194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for the training loop\n",
    "def train_td_model(model, num_episodes):\n",
    "    for episode in range(num_episodes):\n",
    "        # The training loop should include:\n",
    "        # 1. Interacting with the environment\n",
    "        # 2. Computing TD target and TD error\n",
    "        # 3. Updating the model using backpropagation\n",
    "        pass\n",
    "\n",
    "# Placeholder for saving the model\n",
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38ef1c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/Talha/OneDrive - Higher Education Commission/Documents/GitHub/reinforcement_learning/Project/Phase_3_3D_Tic_Tac_Toe/models/td_tictactoe_model.pth'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage\n",
    "num_episodes = 1000  # Number of episodes for training\n",
    "train_td_model(model, num_episodes)  # Train the model\n",
    "\n",
    "# Save the trained model\n",
    "os.makedirs('C:/Users/Talha/OneDrive - Higher Education Commission/Documents/GitHub/reinforcement_learning/Project/Phase_3_3D_Tic_Tac_Toe/models', exist_ok = True)\n",
    "model_path = 'C:/Users/Talha/OneDrive - Higher Education Commission/Documents/GitHub/reinforcement_learning/Project/Phase_3_3D_Tic_Tac_Toe/models/td_tictactoe_model.pth'\n",
    "save_model(model, model_path)\n",
    "\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d4e555",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
