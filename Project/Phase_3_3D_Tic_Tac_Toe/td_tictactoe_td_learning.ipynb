{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e9351a0",
   "metadata": {},
   "source": [
    "# Temporal Difference Learning for 3D Tic Tac Toe\n",
    "\n",
    "This notebook contains the implementation of a Temporal Difference (TD) learning model using a Deep Q-Network (DQN) for playing 3D 4x4x4 Tic Tac Toe. The implementation is based on the approach outlined in the provided paper.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "261768de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Setting Directory\n",
    "os.chdir('C:/Users/Talha/OneDrive - Higher Education Commission/Documents/GitHub/reinforcement_learning/Project/')\n",
    "\n",
    "from python_scripts import state_formulation, utils, algorithm, tictactoe_4x4\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "import torch.nn.init as init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "5a1cd2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rows(input_tensor):\n",
    "    # Get diagonals (across 2 faces),digonals (across 3 faces) and horizontal and vertical rows\n",
    "    diag_two_faces = []\n",
    "    diag_two_faces.extend(\n",
    "        [torch.diagonal(input_tensor[i, :, :]), torch.diagonal(input_tensor[:, i, :]), torch.diagonal(input_tensor[:, :, i]), \n",
    "        torch.diagonal(torch.fliplr(input_tensor)[i, :, :]), torch.diagonal(torch.fliplr(input_tensor)[:, i, :]), torch.diagonal(torch.fliplr(input_tensor)[:, :, i])] \n",
    "        for i in range(input_tensor.shape[0]))\n",
    "    diag_two_faces = [item for sublist in diag_two_faces for item in sublist]\n",
    "    \n",
    "    diag_three_faces = []\n",
    "    diag_three_faces = [[[[input_tensor[i, i, i], input_tensor[3 - i, i, i], input_tensor[i, 3 - i, i], input_tensor[i, i, 3 - i]] \n",
    "                          for i in range(4)][k][j] for j in range(4) for k in range(4)][l:l + 4] for l in range(0, 16, 4)]\n",
    "    diag_three_faces = [torch.tensor([t.item() for t in row]) for row in diag_three_faces]\n",
    "\n",
    "    horizontal_and_vertical_rows = []\n",
    "    horizontal_and_vertical_rows.extend([input_tensor[i, j, :], input_tensor[i, :, j], input_tensor[:, i, j]]\n",
    "                                        for i in range(input_tensor.shape[0]) for j in range(input_tensor.shape[0]))\n",
    "    horizontal_and_vertical_rows = [item for sublist in horizontal_and_vertical_rows for item in sublist]\n",
    "    \n",
    "    return horizontal_and_vertical_rows + diag_two_faces + diag_three_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "cb2576da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 76\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.arange(64).view(4, 4, 4)\n",
    "overall_rows = get_rows(input_tensor)\n",
    "print(f'Number of rows: {len(overall_rows)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "7e166039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0, 1, 2, 3]),\n",
       " tensor([ 0,  4,  8, 12]),\n",
       " tensor([ 0, 16, 32, 48]),\n",
       " tensor([4, 5, 6, 7]),\n",
       " tensor([ 1,  5,  9, 13]),\n",
       " tensor([ 1, 17, 33, 49]),\n",
       " tensor([ 8,  9, 10, 11]),\n",
       " tensor([ 2,  6, 10, 14]),\n",
       " tensor([ 2, 18, 34, 50]),\n",
       " tensor([12, 13, 14, 15]),\n",
       " tensor([ 3,  7, 11, 15]),\n",
       " tensor([ 3, 19, 35, 51]),\n",
       " tensor([16, 17, 18, 19]),\n",
       " tensor([16, 20, 24, 28]),\n",
       " tensor([ 4, 20, 36, 52]),\n",
       " tensor([20, 21, 22, 23]),\n",
       " tensor([17, 21, 25, 29]),\n",
       " tensor([ 5, 21, 37, 53]),\n",
       " tensor([24, 25, 26, 27]),\n",
       " tensor([18, 22, 26, 30]),\n",
       " tensor([ 6, 22, 38, 54]),\n",
       " tensor([28, 29, 30, 31]),\n",
       " tensor([19, 23, 27, 31]),\n",
       " tensor([ 7, 23, 39, 55]),\n",
       " tensor([32, 33, 34, 35]),\n",
       " tensor([32, 36, 40, 44]),\n",
       " tensor([ 8, 24, 40, 56]),\n",
       " tensor([36, 37, 38, 39]),\n",
       " tensor([33, 37, 41, 45]),\n",
       " tensor([ 9, 25, 41, 57]),\n",
       " tensor([40, 41, 42, 43]),\n",
       " tensor([34, 38, 42, 46]),\n",
       " tensor([10, 26, 42, 58]),\n",
       " tensor([44, 45, 46, 47]),\n",
       " tensor([35, 39, 43, 47]),\n",
       " tensor([11, 27, 43, 59]),\n",
       " tensor([48, 49, 50, 51]),\n",
       " tensor([48, 52, 56, 60]),\n",
       " tensor([12, 28, 44, 60]),\n",
       " tensor([52, 53, 54, 55]),\n",
       " tensor([49, 53, 57, 61]),\n",
       " tensor([13, 29, 45, 61]),\n",
       " tensor([56, 57, 58, 59]),\n",
       " tensor([50, 54, 58, 62]),\n",
       " tensor([14, 30, 46, 62]),\n",
       " tensor([60, 61, 62, 63]),\n",
       " tensor([51, 55, 59, 63]),\n",
       " tensor([15, 31, 47, 63]),\n",
       " tensor([ 0,  5, 10, 15]),\n",
       " tensor([ 0, 17, 34, 51]),\n",
       " tensor([ 0, 20, 40, 60]),\n",
       " tensor([12,  9,  6,  3]),\n",
       " tensor([12, 29, 46, 63]),\n",
       " tensor([12, 24, 36, 48]),\n",
       " tensor([16, 21, 26, 31]),\n",
       " tensor([ 4, 21, 38, 55]),\n",
       " tensor([ 1, 21, 41, 61]),\n",
       " tensor([28, 25, 22, 19]),\n",
       " tensor([ 8, 25, 42, 59]),\n",
       " tensor([13, 25, 37, 49]),\n",
       " tensor([32, 37, 42, 47]),\n",
       " tensor([ 8, 25, 42, 59]),\n",
       " tensor([ 2, 22, 42, 62]),\n",
       " tensor([44, 41, 38, 35]),\n",
       " tensor([ 4, 21, 38, 55]),\n",
       " tensor([14, 26, 38, 50]),\n",
       " tensor([48, 53, 58, 63]),\n",
       " tensor([12, 29, 46, 63]),\n",
       " tensor([ 3, 23, 43, 63]),\n",
       " tensor([60, 57, 54, 51]),\n",
       " tensor([ 0, 17, 34, 51]),\n",
       " tensor([15, 27, 39, 51]),\n",
       " tensor([ 0, 21, 42, 63]),\n",
       " tensor([48, 37, 26, 15]),\n",
       " tensor([12, 25, 38, 51]),\n",
       " tensor([ 3, 22, 41, 60])]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "71e07a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   1,   2,   3],\n",
       "        [304, 305, 306, 307],\n",
       "        [608, 609, 610, 611],\n",
       "        [912, 913, 914, 915]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = torch.arange(304).view(1, 304)\n",
    "test_weight = torch.arange(304 ** 2).view(304, 304)\n",
    "\n",
    "test_weight[0:4, 0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e8d7048c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.zeros((304, 304))\n",
    "for i in range(0, 304, 4):\n",
    "    # weights[(i + 4) * i: i + 4, (i + 4) * i: i + 4] = 1 ## --> 0:4, 0:4 --> 5:9, 5:9 --> \n",
    "    weights[i:i+4, i:i+4] = torch.ones(4, 4)\n",
    "print(weights[0:12, 0:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "1ba55757",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StructuredLinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(StructuredLinear, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        # Initialize weights and biases\n",
    "        self.weights = nn.Parameter(torch.zeros((output_size, input_size)))\n",
    "        # self.biases = nn.Parameter(torch.zeros(output_size))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        # Set weights for structured connections\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, self.output_size, 4):\n",
    "                entry = (torch.ones(4, 4))\n",
    "                entry.requires_grad_(True)\n",
    "                self.weights[i: i + 4, i: i + 4] = entry\n",
    "        # Initialize biases\n",
    "        # nn.init.zeros_(self.biases)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.matmul(x, self.weights)\n",
    "\n",
    "class MyNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNeuralNetwork, self).__init__()\n",
    "        self.structured_layer = StructuredLinear(304, 304)\n",
    "        self.second_layer = nn.Linear(304, 32, bias = False)\n",
    "        self.output_layer = nn.Linear(32, 1, bias = False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.structured_layer(x)\n",
    "        x = torch.relu(self.second_layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "model = MyNeuralNetwork()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "760d3665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "MyNeuralNetwork                          [1, 304]                  [1, 1]                    --\n",
       "├─StructuredLinear: 1-1                  [1, 304]                  [1, 304]                  --\n",
       "├─Linear: 1-2                            [1, 304]                  [1, 32]                   9,728\n",
       "├─Linear: 1-3                            [1, 32]                   [1, 1]                    32\n",
       "===================================================================================================================\n",
       "Total params: 9,760\n",
       "Trainable params: 9,760\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.01\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.04\n",
       "Estimated Total Size (MB): 0.04\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_size = (1, 304), col_names = ['input_size', 'output_size', 'num_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fe2ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StructuredLinearLayer(nn.Module):\n",
    "    def __init__(self, num_rows, board_size):\n",
    "        super(StructuredLinearLayer, self).__init__()\n",
    "        self.num_rows = num_rows\n",
    "        self.board_size = board_size\n",
    "    \n",
    "    def createlayer():\n",
    "        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cec3583e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the MLP architecture for the TD learning model\n",
    "class TDNetwork(nn.Module, tictactoe_4x4.TicTacToe4x4x4):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        # Note: Hidden Sizes will be a list. According to the paper, it will be 304, 32\n",
    "        super(TDNetwork, self).__init__()\n",
    "        layers = []\n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.append(nn.Linear(input_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_size = hidden_size\n",
    "        layers.append(nn.Linear(hidden_sizes[-1], output_size))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        feature_map = get_rows(x)\n",
    "        return self.layers(feature_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a13fb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linears = nn.ModuleList([nn.Linear(10, 10) for i in range(10)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ModuleList can act as an iterable, or be indexed using ints\n",
    "        for i, l in enumerate(self.linears):\n",
    "            x = self.linears[i // 2](x) + l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5c406d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TD learning model\n",
    "input_size = 64  # Assuming each space on the 4x4x4 board is represented as a binary (occupied or not)\n",
    "hidden_sizes = [128, 128]  # Hidden layers sizes as per the paper's experimentation\n",
    "output_size = 1  # Output size representing the value function\n",
    "model = TDNetwork(input_size, hidden_sizes, output_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e6fb543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_function = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b63194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for the training loop\n",
    "def train_td_model(model, num_episodes):\n",
    "    for episode in range(num_episodes):\n",
    "        # The training loop should include:\n",
    "        # 1. Interacting with the environment\n",
    "        # 2. Computing TD target and TD error\n",
    "        # 3. Updating the model using backpropagation\n",
    "        pass\n",
    "\n",
    "# Placeholder for saving the model\n",
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38ef1c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/Talha/OneDrive - Higher Education Commission/Documents/GitHub/reinforcement_learning/Project/Phase_3_3D_Tic_Tac_Toe/models/td_tictactoe_model.pth'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage\n",
    "num_episodes = 1000  # Number of episodes for training\n",
    "train_td_model(model, num_episodes)  # Train the model\n",
    "\n",
    "# Save the trained model\n",
    "os.makedirs('C:/Users/Talha/OneDrive - Higher Education Commission/Documents/GitHub/reinforcement_learning/Project/Phase_3_3D_Tic_Tac_Toe/models', exist_ok = True)\n",
    "model_path = 'C:/Users/Talha/OneDrive - Higher Education Commission/Documents/GitHub/reinforcement_learning/Project/Phase_3_3D_Tic_Tac_Toe/models/td_tictactoe_model.pth'\n",
    "save_model(model, model_path)\n",
    "\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d4e555",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
