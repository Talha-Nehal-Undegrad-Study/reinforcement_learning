{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e9351a0",
   "metadata": {},
   "source": [
    "# Temporal Difference Learning for 3D Tic Tac Toe\n",
    "\n",
    "This notebook contains the implementation of a Temporal Difference (TD) learning model using a Deep Q-Network (DQN) for playing 3D 4x4x4 Tic Tac Toe. The implementation is based on the approach outlined in the provided paper.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "261768de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchinfo in c:\\users\\hp\\anaconda3\\envs\\cs6314\\lib\\site-packages (1.8.0)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Setting Directory\n",
    "# os.chdir('C:/Users/Talha/OneDrive - Higher Education Commission/Documents/GitHub/reinforcement_learning/Project/')\n",
    "os.chdir('C:/Users/HP/Documents/GitHub/reinforcement_learning/Project/')\n",
    "\n",
    "from python_scripts import state_formulation, utils, algorithm, tictactoe_4x4\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "!pip install torchinfo\n",
    "from torchinfo import summary\n",
    "import torch.nn.init as init\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97cae957",
   "metadata": {},
   "outputs": [],
   "source": [
    "class customDotProduct(nn.Module):\n",
    "    def __init__(self, input_size, output_size, block_size = 4):\n",
    "        super(customDotProduct, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.block_size = block_size\n",
    "        # Convert structure_weight to nn.Parameter\n",
    "        self.structure_weight = torch.zeros((self.output_size, self.input_size))\n",
    "        self.structure_weight = self.get_block_weights(self.structure_weight, block_size)\n",
    "        self.structure_weight = nn.ParameterList([nn.Parameter(sw.float()) for sw in self.structure_weight])\n",
    "\n",
    "    def get_block_weights(self, weight_list, block_size):\n",
    "        for i in range(0, 304, block_size):\n",
    "            weight_list[i: i + block_size, i: i + block_size] = init.xavier_normal_(torch.randn(block_size, block_size))\n",
    "        learnable_blocks = [weight_list[i:i + block_size, i:i + block_size] for i in range(0, weight_list.shape[0], block_size)]\n",
    "        updated = [block for block in learnable_blocks]\n",
    "        return updated\n",
    "    \n",
    "    def forward(self, feature_map):\n",
    "        self.feature_map = [fm.float() for fm in feature_map]\n",
    "        # Calculate dot products and concatenate along dim = 1\n",
    "        concatenated_products = torch.cat([torch.matmul(fm.unsqueeze(0), sw) for fm, sw in zip(self.feature_map, self.structure_weight)], dim = 1)\n",
    "        return concatenated_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8005ce71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing Code\n",
    "# weights = torch.zeros((304, 304))\n",
    "\n",
    "# block_size = 4\n",
    "# for i in range(0, 304, block_size):\n",
    "#     weights[i: i + block_size, i: i + block_size] = torch.ones(block_size, block_size)\n",
    "# learnable_blocks = [weights[i:i + block_size, i:i + block_size] for i in range(0, weights.shape[0], block_size)]\n",
    "# weights = [init.xavier_normal_(block) for block in learnable_blocks]\n",
    "\n",
    "# print(f'Before Update: Weights = {weights[0]} \\n')\n",
    "\n",
    "# # Assume some loss function and optimizer have been defined\n",
    "# custom_dot_product_module = customDotProduct(304, 304)\n",
    "# loss_function = nn.MSELoss()\n",
    "# optimizer = torch.optim.SGD(custom_dot_product_module.parameters(), lr = 0.01)\n",
    "\n",
    "# # Example training loop iteration\n",
    "# optimizer.zero_grad()  # Clear gradients\n",
    "# output = custom_dot_product_module(rows)  # Perform forward pass\n",
    "# loss = loss_function(output, torch.randn(1, 304))  # Compute loss\n",
    "# loss.backward()  # Perform backward pass\n",
    "# optimizer.step()  # Update weights\n",
    "# print(f'After Update: Weights = {custom_dot_product_module.structure_weight[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ba55757",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StructuredLinear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StructuredLinear, self).__init__()\n",
    "\n",
    "    def get_rows(self, input_tensor):\n",
    "        # Get diagonals (across 2 faces),digonals (across 3 faces) and horizontal and vertical rows\n",
    "        diag_two_faces = []\n",
    "        diag_two_faces.extend(\n",
    "            [torch.diagonal(input_tensor[i, :, :]), torch.diagonal(input_tensor[:, i, :]), torch.diagonal(input_tensor[:, :, i]), \n",
    "            torch.diagonal(torch.fliplr(input_tensor)[i, :, :]), torch.diagonal(torch.fliplr(input_tensor)[:, i, :]), torch.diagonal(torch.fliplr(input_tensor)[:, :, i])] \n",
    "            for i in range(input_tensor.shape[0]))\n",
    "        diag_two_faces = [item for sublist in diag_two_faces for item in sublist]\n",
    "        \n",
    "        diag_three_faces = []\n",
    "        diag_three_faces = [[[[input_tensor[i, i, i], input_tensor[3 - i, i, i], input_tensor[i, 3 - i, i], input_tensor[i, i, 3 - i]] \n",
    "                            for i in range(4)][k][j] for j in range(4) for k in range(4)][l:l + 4] for l in range(0, 16, 4)]\n",
    "        diag_three_faces = [torch.tensor([t.item() for t in row]) for row in diag_three_faces]\n",
    "\n",
    "        horizontal_and_vertical_rows = []\n",
    "        horizontal_and_vertical_rows.extend([input_tensor[i, j, :], input_tensor[i, :, j], input_tensor[:, i, j]]\n",
    "                                            for i in range(input_tensor.shape[0]) for j in range(input_tensor.shape[0]))\n",
    "        horizontal_and_vertical_rows = [item for sublist in horizontal_and_vertical_rows for item in sublist]\n",
    "        \n",
    "        return horizontal_and_vertical_rows + diag_two_faces + diag_three_faces\n",
    "\n",
    "    def forward(self, x):\n",
    "        rows = self.get_rows(x)\n",
    "        return rows\n",
    "\n",
    "class MyNeuralNetwork(nn.Module, tictactoe_4x4.TicTacToe4x4x4):\n",
    "    def __init__(self, num_detectors):\n",
    "        super(MyNeuralNetwork, self).__init__()\n",
    "\n",
    "        self.num_detectors = num_detectors\n",
    "        self.structured_layer = StructuredLinear()\n",
    "        \n",
    "        self.custom_operation_layer = customDotProduct(input_size = num_detectors * 4, output_size = num_detectors * 4)\n",
    "\n",
    "        self.second_layer = nn.Linear(num_detectors * 4, 32, bias = False)\n",
    "        init.xavier_normal_(self.second_layer.weight)\n",
    "\n",
    "        self.output_layer = nn.Linear(32, 1, bias = False)\n",
    "        self.act = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.structured_layer(x)\n",
    "        x = self.custom_operation_layer(x)\n",
    "        x = self.act(x) # --> Tanh\n",
    "        x = self.second_layer(x)\n",
    "        x = self.act(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "    \n",
    "# Example usage\n",
    "model = MyNeuralNetwork()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "760d3665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "MyNeuralNetwork                          [4, 4, 4]                 [1, 1]                    --\n",
       "├─StructuredLinear: 1-1                  [4, 4, 4]                 [4]                       --\n",
       "├─customDotProduct: 1-2                  [4]                       [1, 304]                  1,216\n",
       "├─Tanh: 1-3                              [1, 304]                  [1, 304]                  --\n",
       "├─Linear: 1-4                            [1, 304]                  [1, 32]                   9,728\n",
       "├─Tanh: 1-5                              [1, 32]                   [1, 32]                   --\n",
       "├─Linear: 1-6                            [1, 32]                   [1, 1]                    32\n",
       "===================================================================================================================\n",
       "Total params: 10,976\n",
       "Trainable params: 10,976\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.01\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.04\n",
       "Estimated Total Size (MB): 0.04\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_size = [4, 4, 4], col_names = ['input_size', 'output_size', 'num_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3be4ac95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyNeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e6fb543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "loss_function = nn.MSELoss()\n",
    "EPSILON = 0.1\n",
    "GAMMA = 0.9\n",
    "reward = torch.randint(low = 0, high = 2, size = (4, 4, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b63194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(current_state):\n",
    "    action_space = torch.stack(torch.where(current_state == 0), -1)\n",
    "    afterstates = []\n",
    "    for i in action_space:\n",
    "        afterstates.append(current_state.detach().clone())\n",
    "        afterstates[-1][tuple(i)] = 1\n",
    "    return zip(action_space, torch.stack(afterstates))\n",
    "\n",
    "def e_greedy(current_state, temp_dict):\n",
    "    if np.random.random() > EPSILON:\n",
    "        return max(temp_dict, key = lambda k: temp_dict[k])\n",
    "    action_space = torch.stack(torch.where(current_state == 0), -1)\n",
    "    index = torch.randint(low = 0, high = len(action_space), size = (1,))\n",
    "    return action_space[index]\n",
    "\n",
    "def train_td_model(model, num_episodes):\n",
    "    for episode in tqdm(range(num_episodes)):\n",
    "        current_state = torch.randint(low = -1, high = 2, size = (4, 4, 4))\n",
    "        prev_afterstate = None\n",
    "        for t in range(1000):\n",
    "            if 0 not in current_state:\n",
    "                break\n",
    "            temp_dict = {}\n",
    "            for a, afterstate in get_next(current_state):\n",
    "                temp_dict[a] = model.forward(afterstate)\n",
    "            action = e_greedy(current_state, temp_dict)\n",
    "\n",
    "            current_state[action] = 1\n",
    "            if t != 0:\n",
    "                v_new = reward[prev_afterstate] + (GAMMA * model.forward(current_state))\n",
    "                v = model.forward(prev_afterstate)\n",
    "                loss = loss_function(v, v_new)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            prev_afterstate = current_state\n",
    "            if 0 not in current_state:\n",
    "                break\n",
    "            current_state[torch.where(current_state == 0)] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38ef1c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa12d7249a4143e4bebfa1d254b12326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example usage\n",
    "num_episodes = 1000  # Number of episodes for training\n",
    "train_td_model(model, num_episodes)  # Train the model\n",
    "\n",
    "# Save the trained model\n",
    "# os.makedirs('C:/Users/Talha/OneDrive - Higher Education Commission/Documents/GitHub/reinforcement_learning/Project/Phase_3_3D_Tic_Tac_Toe/models', exist_ok = True)\n",
    "# model_path = 'C:/Users/Talha/OneDrive - Higher Education Commission/Documents/GitHub/reinforcement_learning/Project/Phase_3_3D_Tic_Tac_Toe/models/td_tictactoe_model.pth'\n",
    "# save_model(model, model_path)\n",
    "\n",
    "# model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d4e555",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
